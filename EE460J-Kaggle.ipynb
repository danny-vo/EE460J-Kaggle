{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install numpy pandas sklearn --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read in the csv data\n",
    "train_data = pd.read_csv(\"train_final.csv\")\n",
    "test_data = pd.read_csv(\"test_final.csv\")\n",
    "# Example the contents\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = train_data.loc[:, \"Y\":\"Y\"].values\n",
    "Y = train_data.loc[:, \"f1\":\"f24\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.33, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmTrain = xgb.DMatrix(X_train, label=Y_train)\n",
    "dmTest = xgb.DMatrix(X_test, label=Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_train = np.mean(Y_train)\n",
    "base_predict = np.ones(Y_test.shape) * mean_train\n",
    "mae_base = mean_absolute_error(Y_test, base_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-mae:46888.8\n",
      "Will train until Test-mae hasn't improved in 10 rounds.\n",
      "[1]\tTest-mae:49909.4\n",
      "[2]\tTest-mae:52166.4\n",
      "[3]\tTest-mae:53786.2\n",
      "[4]\tTest-mae:54952.2\n",
      "[5]\tTest-mae:55778.1\n",
      "[6]\tTest-mae:56363.9\n",
      "[7]\tTest-mae:56775.4\n",
      "[8]\tTest-mae:57064.9\n",
      "[9]\tTest-mae:57268.4\n",
      "[10]\tTest-mae:57410.9\n",
      "Stopping. Best iteration:\n",
      "[0]\tTest-mae:46888.8\n",
      "\n",
      "Best MAE: 46888.76 with 1 rounds\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    'eta':.3,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    'objective': 'reg:linear',\n",
    "    'silent': 1,\n",
    "}\n",
    "params['eval_metric'] = \"mae\"\n",
    "boost_rounds = 999\n",
    "\n",
    "model = xgb.train(\n",
    "    params,\n",
    "    dmTrain,\n",
    "    num_boost_round=boost_rounds,\n",
    "    evals=[(dmTest, \"Test\")],\n",
    "    early_stopping_rounds=10,\n",
    "    verbose_eval=False\n",
    ")\n",
    "\n",
    "print(\"Best MAE: {:.2f} with {} rounds\".format(\n",
    "                 model.best_score,\n",
    "                 model.best_iteration+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(0, 10)\n",
    "    for min_child_weight in range(0, 10)\n",
    "]\n",
    "\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "    \n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dmTrain,\n",
    "        num_boost_round=boost_rounds,\n",
    "        seed=69,\n",
    "        nfold=5,\n",
    "        metrics={'mae'},\n",
    "        early_stopping_rounds=1000,\n",
    "        verbose_eval=1000\n",
    "    )\n",
    "    \n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (max_depth, min_child_weight)\n",
    "        \n",
    "print(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters subsample and colsample_bytree"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
